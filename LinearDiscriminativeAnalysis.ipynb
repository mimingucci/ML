{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4zkfYKXwI7BnUAltMMhhB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimingucci/ML/blob/main/LinearDiscriminativeAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Bayes's rules to turn P(X|Y=k) into P(Y=k|X)<br/>\n",
        "Suppose we have a classification task with K unordered classes, represented by k=1,…,K.\n",
        "<br/>\n",
        "1.Estimate the density of the predictors conditional on the target belonging to each class P(x|y=k)\n",
        "<br/>\n",
        "2.Estimate the prior probability that a target belongs to any given class P(y=k)\n",
        "<br/>\n",
        "3.Using Bayes’ rule, calculate the posterior probability that the target belongs to any given class.\n",
        "<br/>\n",
        "$P(y=k|x)\\sim P(x|y=k)P(y=k)$ for k=1, 2, ..., K\n",
        "<br/>\n",
        "We then classify observation n as being from the class for which P(y=k|x) is greatest. In math, $\\widehat{\\gamma }=arg maxP(y=k|x)$ for k=1, 2, ..., K\n",
        "\n"
      ],
      "metadata": {
        "id": "6MhtqdmTtULQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Priors P(y=k)<br/>\n",
        "$\\widehat{\\pi _{k}}=\\frac{N_{k}}{N}$"
      ],
      "metadata": {
        "id": "4axzP8ivwh0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In LDA, assume <br/>\n",
        "$x|y=k\\sim MVN(\\mu _{k}, \\Sigma )$<br/>\n",
        "here, $\\mu _{k}$ is unique mean vector of each class k, $\\Sigma$ is covariance matrix<br/>\n",
        "We have following formula:<br/>\n",
        "$\\widehat{\\Sigma }=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{k=1}^{K}I_{nk}(x_{n}-\\mu _{k})(x_{n}-\\mu _{k})^{T}$\n",
        "<br/>\n",
        "$\\widehat{\\mu _{k}}=\\overline{x_{k}}$"
      ],
      "metadata": {
        "id": "m9zGD15CxQ_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkF2NGhMMhNl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "wine = datasets.load_wine()\n",
        "X, y = wine.data, wine.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LDA:\n",
        "\n",
        "    ## Fitting the model\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        ## Record info\n",
        "        self.N, self.D = X.shape\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        ## prior probabilities\n",
        "        self.unique_y, unique_y_counts = np.unique(self.y, return_counts = True) # returns unique y and counts\n",
        "        self.pi_ks = unique_y_counts/self.N\n",
        "\n",
        "        self.mu_ks = []\n",
        "        self.Sigma = np.zeros((self.D, self.D))\n",
        "        for i, k in enumerate(self.unique_y):\n",
        "            X_k = self.X[self.y == k]\n",
        "            mu_k = X_k.mean(0).reshape(self.D, 1)\n",
        "            self.mu_ks.append(mu_k)\n",
        "\n",
        "            for x_n in X_k:\n",
        "                x_n = x_n.reshape(-1,1)\n",
        "                x_n_minus_mu_k = (x_n - mu_k)\n",
        "                self.Sigma += np.dot(x_n_minus_mu_k, x_n_minus_mu_k.T)\n",
        "\n",
        "        self.Sigma /= self.N\n",
        "\n",
        "\n",
        "    ## classifications\n",
        "\n",
        "    def _mvn_density(self, x_n, mu_k, Sigma):\n",
        "        x_n_minus_mu_k = (x_n - mu_k)\n",
        "        density = np.exp(-(1/2)*x_n_minus_mu_k.T @ np.linalg.inv(Sigma) @ x_n_minus_mu_k)\n",
        "        return density\n",
        "\n",
        "    def classify(self, X_test):\n",
        "\n",
        "        y_n = np.empty(len(X_test))\n",
        "        for i, x_n in enumerate(X_test):\n",
        "\n",
        "            x_n = x_n.reshape(-1, 1)\n",
        "            p_ks = np.empty(len(self.unique_y))\n",
        "\n",
        "            for j, k in enumerate(self.unique_y):\n",
        "                p_x_given_y = self._mvn_density(x_n, self.mu_ks[j], self.Sigma)\n",
        "                p_y_given_x = self.pi_ks[j]*p_x_given_y\n",
        "                p_ks[j] = p_y_given_x\n",
        "\n",
        "            y_n[i] = self.unique_y[np.argmax(p_ks)]\n",
        "\n",
        "        return y_n\n"
      ],
      "metadata": {
        "id": "pGcmUJBfNKbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA()\n",
        "lda.fit(X, y)\n",
        "yhat = lda.classify(X)\n",
        "print(np.mean(yhat == y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLXOAq_SPBae",
        "outputId": "47ff7be6-1357-49b6-d132-a5327055c93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6def5fb2ba3b>:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  p_ks[j] = p_y_given_x\n"
          ]
        }
      ]
    }
  ]
}