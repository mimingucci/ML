{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgw4ZDhN40WItekMh/dpGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimingucci/ML/blob/main/QuadraticDiscriminativeAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to Linear Discriminative Analysis(LDA) but each class has idividual covariance matrix <br/>\n",
        "$\\widehat{\\Sigma _{k}}=\\frac{1}{N_{k}}\\sum_{n\\in C_{k}}^{}(x_{n}-\\mu _{k})(x_{n}-\\mu _{k})^{T}$ and others are same"
      ],
      "metadata": {
        "id": "W49mEXbU3wDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:<br/>\n",
        "PDF of MVN has formula : $(2\\pi )^{-k/2}det(\\Sigma )^{-1/2}exp(-\\frac{1}{2}(x-\\mu )^{T}\\Sigma ^{-1}(x-\\mu ))$ <br/>condition: $\\mu \\in R^{k} $ and $\\Sigma \\in R^{k * k}$"
      ],
      "metadata": {
        "id": "ygo3wCO-9B_L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xgphoSnM28M3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class QDA:\n",
        "\n",
        "    ## Fitting the model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        ## Record info\n",
        "        self.N, self.D = X.shape\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "\n",
        "        ## Get prior probabilities\n",
        "        self.unique_y, unique_y_counts = np.unique(self.y, return_counts = True) # returns unique y and counts\n",
        "        self.pi_ks = unique_y_counts/self.N\n",
        "\n",
        "\n",
        "        ## Get mu and Sigma for each class\n",
        "        self.mu_ks = []\n",
        "        self.Sigma_ks = []\n",
        "        for i, k in enumerate(self.unique_y):\n",
        "\n",
        "            X_k = self.X[self.y == k]\n",
        "            mu_k = X_k.mean(0).reshape(self.D, 1)\n",
        "            self.mu_ks.append(mu_k)\n",
        "\n",
        "            Sigma_k = np.zeros((self.D, self.D))\n",
        "            for x_n in X_k:\n",
        "                x_n = x_n.reshape(-1,1)\n",
        "                x_n_minus_mu_k = (x_n - mu_k)\n",
        "                Sigma_k += np.dot(x_n_minus_mu_k, x_n_minus_mu_k.T)\n",
        "            self.Sigma_ks.append(Sigma_k/len(X_k))\n",
        "\n",
        "    ## Making classifications\n",
        "\n",
        "    def _mvn_density(self, x_n, mu_k, Sigma_k):\n",
        "        x_n_minus_mu_k = (x_n - mu_k)\n",
        "        density = np.linalg.det(Sigma_k)**(-1/2) * np.exp(-(1/2)*x_n_minus_mu_k.T @ np.linalg.inv(Sigma_k) @ x_n_minus_mu_k)\n",
        "        return density\n",
        "\n",
        "    def classify(self, X_test):\n",
        "\n",
        "        y_n = np.empty(len(X_test))\n",
        "        for i, x_n in enumerate(X_test):\n",
        "\n",
        "            x_n = x_n.reshape(-1, 1)\n",
        "            p_ks = np.empty(len(self.unique_y))\n",
        "\n",
        "            for j, k in enumerate(self.unique_y):\n",
        "\n",
        "                p_x_given_y = self._mvn_density(x_n, self.mu_ks[j], self.Sigma_ks[j])\n",
        "                p_y_given_x = self.pi_ks[j]*p_x_given_y\n",
        "                p_ks[j] = p_y_given_x\n",
        "\n",
        "            y_n[i] = self.unique_y[np.argmax(p_ks)]\n",
        "\n",
        "        return y_n\n"
      ]
    }
  ]
}